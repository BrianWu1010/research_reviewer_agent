[
  {
    "title": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration",
    "summary": "What drives an agent to explore the world while also maintaining control over\nthe environment? From a child at play to scientists in the lab, intelligent\nagents must balance curiosity (the drive to seek knowledge) with competence\n(the drive to master and control the environment). Bridging cognitive theories\nof intrinsic motivation with reinforcement learning, we ask how evolving\ninternal representations mediate the trade-off between curiosity (novelty or\ninformation gain) and competence (empowerment). We compare two model-based\nagents using handcrafted state abstractions (Tabular) or learning an internal\nworld model (Dreamer). The Tabular agent shows curiosity and competence guide\nexploration in distinct patterns, while prioritizing both improves exploration.\nThe Dreamer agent reveals a two-way interaction between exploration and\nrepresentation learning, mirroring the developmental co-evolution of curiosity\nand competence. Our findings formalize adaptive exploration as a balance\nbetween pursuing the unknown and the controllable, offering insights for\ncognitive theories and efficient reinforcement learning.",
    "url": "http://arxiv.org/abs/2507.08210v1",
    "authors": [
      "Fryderyk Mantiuk",
      "Hanqi Zhou",
      "Charley M. Wu"
    ],
    "published": "2025-07-10"
  },
  {
    "title": "Optimizing Model Splitting and Device Task Assignment for Deceptive Signal Assisted Private Multi-hop Split Learning",
    "summary": "In this paper, deceptive signal-assisted private split learning is\ninvestigated. In our model, several edge devices jointly perform collaborative\ntraining, and some eavesdroppers aim to collect the model and data information\nfrom devices. To prevent the eavesdroppers from collecting model and data\ninformation, a subset of devices can transmit deceptive signals. Therefore, it\nis necessary to determine the subset of devices used for deceptive signal\ntransmission, the subset of model training devices, and the models assigned to\neach model training device. This problem is formulated as an optimization\nproblem whose goal is to minimize the information leaked to eavesdroppers while\nmeeting the model training energy consumption and delay constraints. To solve\nthis problem, we propose a soft actor-critic deep reinforcement learning\nframework with intrinsic curiosity module and cross-attention (ICM-CA) that\nenables a centralized agent to determine the model training devices, the\ndeceptive signal transmission devices, the transmit power, and sub-models\nassigned to each model training device without knowing the position and\nmonitoring probability of eavesdroppers. The proposed method uses an ICM module\nto encourage the server to explore novel actions and states and a CA module to\ndetermine the importance of each historical state-action pair thus improving\ntraining efficiency. Simulation results demonstrate that the proposed method\nimproves the convergence rate by up to 3x and reduces the information leaked to\neavesdroppers by up to 13% compared to the traditional SAC algorithm.",
    "url": "http://arxiv.org/abs/2507.07323v1",
    "authors": [
      "Dongyu Wei",
      "Xiaoren Xu",
      "Yuchen Liu",
      "H. Vincent Poor",
      "Mingzhe Chen"
    ],
    "published": "2025-07-09"
  },
  {
    "title": "Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration",
    "summary": "Imitation learning is a central problem in reinforcement learning where the\ngoal is to learn a policy that mimics the expert's behavior. In practice, it is\noften challenging to learn the expert policy from a limited number of\ndemonstrations accurately due to the complexity of the state space. Moreover,\nit is essential to explore the environment and collect data to achieve\nbeyond-expert performance. To overcome these challenges, we propose a novel\nimitation learning algorithm called Imitation Learning with Double Exploration\n(ILDE), which implements exploration in two aspects: (1) optimistic policy\noptimization via an exploration bonus that rewards state-action pairs with high\nuncertainty to potentially improve the convergence to the expert policy, and\n(2) curiosity-driven exploration of the states that deviate from the\ndemonstration trajectories to potentially yield beyond-expert performance.\nEmpirically, we demonstrate that ILDE outperforms the state-of-the-art\nimitation learning algorithms in terms of sample efficiency and achieves\nbeyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations\nthan in previous work. We also provide a theoretical justification of ILDE as\nan uncertainty-regularized policy optimization method with optimistic\nexploration, leading to a regret growing sublinearly in the number of episodes.",
    "url": "http://arxiv.org/abs/2506.20307v1",
    "authors": [
      "Heyang Zhao",
      "Xingrui Yu",
      "David M. Bossens",
      "Ivor W. Tsang",
      "Quanquan Gu"
    ],
    "published": "2025-06-25"
  },
  {
    "title": "On the origins of oxygen: ALMA and JWST characterise the multi-phase, metal-enriched, star-bursting medium within a 'normal' $z > 11$ galaxy",
    "summary": "The unexpectedly high abundance of galaxies at $z > 11$ revealed by JWST has\nsparked a debate on the nature of early galaxies and the physical mechanisms\nregulating their formation. The Atacama Large Millimeter/submillimeter Array\n(ALMA) has begun to provide vital insights on their gas and dust content, but\nso far only for extreme 'blue monsters'. Here we present new, deep ALMA\nobservations of JADES-GS-z11-0, a more typical (sub-$L^*$) $z > 11$ galaxy that\nbridges the discovery space of JWST and the Hubble Space Telescope. These data\nconfirm the presence of the [O III] 88 $\\mu$m line at $4.5\\sigma$ significance,\nprecisely at the redshift of several faint emission lines previously seen with\nJWST/NIRSpec, while the underlying dust continuum remains undetected ($F_\\nu <\n9.0 \\, \\mathrm{\\mu Jy}$), implying an obscured star formation rate (SFR) of\n$\\text{SFR}_\\text{IR} \\lesssim 6 \\, \\mathrm{M_\\odot \\, yr^{-1}}$ and dust mass\nof $M_\\text{dust} \\lesssim 1.0 \\times 10^{6} \\, \\mathrm{M_\\odot}$ (all\n$3\\sigma$). The accurate ALMA redshift of $z_\\text{[O III]} = 11.1221 \\pm\n0.0006$ ($\\gtrsim \\! 5\\times$ refined over NIRSpec) helps confirm that\nredshifts measured purely from the Lyman-$\\alpha$ break, even\nspectroscopically, should properly take into account the effects of potential\ndamped Lyman-$\\alpha$ absorption (DLA) systems to avoid systematic\noverestimates of up to $\\Delta z \\approx 0.5$. The [O III] 88 $\\mu$m luminosity\nof $L_\\text{[O III]} = (1.0 \\pm 0.3) \\times 10^{8} \\, \\mathrm{L_\\odot}$,\nmeanwhile, agrees well with the scaling relation for local metal-poor dwarfs\ngiven the SFR measured by NIRCam, NIRSpec, and MIRI. The spatially resolved\nMIRI and ALMA emission also underscores that JADES-GS-z11-0 is likely to\nconsist of two low-mass components that are undergoing strong bursts of star\nformation yet are already pre-enriched in oxygen (~30% solar), only 400 Myr\nafter the Big Bang.",
    "url": "http://arxiv.org/abs/2507.22888v1",
    "authors": [
      "Joris Witstok",
      "Renske Smit",
      "William M. Baker",
      "Pierluigi Rinaldi",
      "Kevin N. Hainline",
      "Hiddo S. B. Algera",
      "Santiago Arribas",
      "Tom J. L. C. Bakx",
      "Andrew J. Bunker",
      "Stefano Carniani",
      "St\u00e9phane Charlot",
      "Jacopo Chevallard",
      "Mirko Curti",
      "Emma Curtis-Lake",
      "Daniel J. Eisenstein",
      "Kasper E. Heintz",
      "Jakob M. Helton",
      "Gareth C. Jones",
      "Roberto Maiolino",
      "Michael V. Maseda",
      "Pablo G. P\u00e9rez-Gonz\u00e1lez",
      "Clara L. Pollock",
      "Brant E. Robertson",
      "Aayush Saxena",
      "Jan Scholtz",
      "Irene Shivaei",
      "Fengwu Sun",
      "Sandro Tacchella",
      "Hannah \u00dcbler",
      "Darach Watson",
      "Chris J. Willott",
      "Zihao Wu"
    ],
    "published": "2025-07-30"
  },
  {
    "title": "Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning",
    "summary": "In-context learning (ICL) is a critical emerging capability of large language\nmodels (LLMs), enabling few-shot learning during inference by including a few\ndemonstrations (demos) in the prompt. However, it has been found that ICL's\nperformance can be sensitive to the choices of demos and their order. This\npaper investigates an unexplored new positional bias of ICL for the first time:\nwe observe that the predictions and accuracy can drift drastically when the\npositions of demos, the system prompt, and the user message in LLM input are\nvaried. We refer to this bias as DEMOS' POSITION IN PROMPT (DPP) bias. We\ndesign a systematic evaluation pipeline to study this type of positional bias\nacross classification, question answering, summarization, and reasoning tasks.\nWe introduce two metrics, ACCURACY-CHANGE and PREDICTION-CHANGE, to quantify\nnet gains and output volatility induced by changes in the demos' position.\nExtensive experiments on ten LLMs from four open-source model families (QWEN,\nLLAMA3, MISTRAL, COHERE) verify that the bias significantly affects their\naccuracy and predictions: placing demos at the start of the prompt yields the\nmost stable and accurate outputs with gains of up to +6 points. In contrast,\nplacing demos at the end of the user message flips over 30\\% of predictions\nwithout improving correctness on QA tasks. Smaller models are most affected by\nthis sensitivity, though even large models remain marginally affected on\ncomplex tasks.",
    "url": "http://arxiv.org/abs/2507.22887v1",
    "authors": [
      "Kwesi Cobbina",
      "Tianyi Zhou"
    ],
    "published": "2025-07-30"
  },
  {
    "title": "Viser: Imperative, Web-based 3D Visualization in Python",
    "summary": "We present Viser, a 3D visualization library for computer vision and\nrobotics. Viser aims to bring easy and extensible 3D visualization to Python:\nwe provide a comprehensive set of 3D scene and 2D GUI primitives, which can be\nused independently with minimal setup or composed to build specialized\ninterfaces. This technical report describes Viser's features, interface, and\nimplementation. Key design choices include an imperative-style API and a\nweb-based viewer, which improve compatibility with modern programming patterns\nand workflows.",
    "url": "http://arxiv.org/abs/2507.22885v1",
    "authors": [
      "Brent Yi",
      "Chung Min Kim",
      "Justin Kerr",
      "Gina Wu",
      "Rebecca Feng",
      "Anthony Zhang",
      "Jonas Kulhanek",
      "Hongsuk Choi",
      "Yi Ma",
      "Matthew Tancik",
      "Angjoo Kanazawa"
    ],
    "published": "2025-07-30"
  },
  {
    "title": "Deep reinforcement learning for efficient exploration of combinatorial structural design spaces",
    "summary": "This paper proposes a reinforcement learning framework for performance-driven\nstructural design that combines bottom-up design generation with learned\nstrategies to efficiently search large combinatorial design spaces. Motivated\nby the limitations of conventional top-down approaches such as optimization,\nthe framework instead models structures as compositions of predefined elements,\naligning form finding with practical constraints like constructability and\ncomponent reuse. With the formulation of the design task as a sequential\ndecision-making problem and a human learning inspired training algorithm, the\nmethod adapts reinforcement learning for structural design. The framework is\ndemonstrated by designing steel braced truss frame cantilever structures, where\ntrained policies consistently generate distinct, high-performing designs that\ndisplay structural performance and material efficiency with the use of\nstructural strategies that align with known engineering principles. Further\nanalysis shows that the agent efficiently narrows its search to promising\nregions of the design space, revealing transferable structural knowledge.",
    "url": "http://arxiv.org/abs/2507.22804v1",
    "authors": [
      "Chloe S. H. Hong",
      "Keith J. Lee",
      "Caitlin T. Mueller"
    ],
    "published": "2025-07-30"
  },
  {
    "title": "HOLA: Enhancing Audio-visual Deepfake Detection via Hierarchical Contextual Aggregations and Efficient Pre-training",
    "summary": "Advances in Generative AI have made video-level deepfake detection\nincreasingly challenging, exposing the limitations of current detection\ntechniques. In this paper, we present HOLA, our solution to the Video-Level\nDeepfake Detection track of 2025 1M-Deepfakes Detection Challenge. Inspired by\nthe success of large-scale pre-training in the general domain, we first scale\naudio-visual self-supervised pre-training in the multimodal video-level\ndeepfake detection, which leverages our self-built dataset of 1.81M samples,\nthereby leading to a unified two-stage framework. To be specific, HOLA features\nan iterative-aware cross-modal learning module for selective audio-visual\ninteractions, hierarchical contextual modeling with gated aggregations under\nthe local-global perspective, and a pyramid-like refiner for scale-aware\ncross-grained semantic enhancements. Moreover, we propose the pseudo supervised\nsingal injection strategy to further boost model performance. Extensive\nexperiments across expert models and MLLMs impressivly demonstrate the\neffectiveness of our proposed HOLA. We also conduct a series of ablation\nstudies to explore the crucial design factors of our introduced components.\nRemarkably, our HOLA ranks 1st, outperforming the second by 0.0476 AUC on the\nTestA set.",
    "url": "http://arxiv.org/abs/2507.22781v1",
    "authors": [
      "Xuecheng Wu",
      "Danlei Huang",
      "Heli Sun",
      "Xinyi Yin",
      "Yifan Wang",
      "Hao Wang",
      "Jia Zhang",
      "Fei Wang",
      "Peihao Guo",
      "Suyu Xing",
      "Junxiao Xue",
      "Liang He"
    ],
    "published": "2025-07-30"
  },
  {
    "title": "Resource-Efficient Adaptation of Large Language Models for Text Embeddings via Prompt Engineering and Contrastive Fine-tuning",
    "summary": "Large Language Models (LLMs) have become a cornerstone in Natural Language\nProcessing (NLP), achieving impressive performance in text generation. Their\ntoken-level representations capture rich, human-aligned semantics. However,\npooling these vectors into a text embedding discards crucial information.\nNevertheless, many non-generative downstream tasks, such as clustering,\nclassification, or retrieval, still depend on accurate and controllable\nsentence- or document-level embeddings. We explore several adaptation\nstrategies for pre-trained, decoder-only LLMs: (i) various aggregation\ntechniques for token embeddings, (ii) task-specific prompt engineering, and\n(iii) text-level augmentation via contrastive fine-tuning. Combining these\ncomponents yields state-of-the-art performance on the English clustering track\nof the Massive Text Embedding Benchmark (MTEB). An analysis of the attention\nmap further shows that fine-tuning shifts focus from prompt tokens to\nsemantically relevant words, indicating more effective compression of meaning\ninto the final hidden state. Our experiments demonstrate that LLMs can be\neffectively adapted as text embedding models through a combination of prompt\nengineering and resource-efficient contrastive fine-tuning on synthetically\ngenerated positive pairs.",
    "url": "http://arxiv.org/abs/2507.22729v1",
    "authors": [
      "Benedikt Roth",
      "Stephan Rappensperger",
      "Tianming Qiu",
      "Hamza Imamovi\u0107",
      "Julian W\u00f6rmann",
      "Hao Shen"
    ],
    "published": "2025-07-30"
  }
]